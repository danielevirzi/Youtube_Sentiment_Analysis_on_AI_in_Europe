{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing of Translated and Scraped Comments for Fine-Tuning\n",
    "\n",
    "This file is used to process/clean the translated comments aswell as the comments we are going to use in inference.\n",
    "The idea is that we want to fine-tune and inference using the models on the same kind of preprocessed data for all languages. Note that we are not using textblob for spell correction here, as it doesn't really work with languages other than english. We tested on german and the comments didn't make any sense anymore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import pandas as pd \n",
    "import regex as re\n",
    "import glob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "language = 'french'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in single file\n",
    "comments = pd.read_csv('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in multiple files\n",
    "path = 'Comments DB/{}/TranslatedFromEnglish/*.csv'.format(language)\n",
    "\n",
    "# Use glob to get all the .csv files in the folder\n",
    "csv_files = glob.glob(path)\n",
    "\n",
    "# Initialize an empty list to hold the DataFrames\n",
    "dataframes = []\n",
    "\n",
    "# Loop over the list of csv files\n",
    "for file in csv_files:\n",
    "    # Read the csv file into a DataFrame\n",
    "    df = pd.read_csv(file)\n",
    "    # Append the DataFrame to the list\n",
    "    dataframes.append(df)\n",
    "\n",
    "# Concatenate all DataFrames in the list into a single DataFrame\n",
    "comments = pd.concat(dataframes, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After translation, we still have to process the comments into the correct format ; i.e. the same we used on the english comments when we labelled them.\n",
    "# In particular, we still have to\n",
    "# remove stopwords\n",
    "# Remove all special characters except for ., ,, ?, !, /, (, and )\n",
    "# Remove all special characters except for ., ,, ?, !, /, (, and )\n",
    "# # Replace ., /, (, and ) with whitespace\n",
    "\n",
    "\n",
    "# Remove empty comments\n",
    "comments = comments[comments['Comment'].notnull()]\n",
    "\n",
    "\n",
    "comments['Comment'] = comments['Comment'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stopwords.words(language))]))\n",
    "if language == 'french':\n",
    "    pattern = r'[^a-zA-Z0-9\\s.,?!/()àâäéèêëîïôöùûüÿçÀÂÄÉÈÊËÎÏÔÖÙÛÜŸÇ]'\n",
    "elif language == 'german':\n",
    "    pattern = r'[^a-zA-Z0-9\\s.,?!/()äöüßÄÖÜ]'\n",
    "elif language == 'spanish':\n",
    "    pattern= r'[^a-zA-Z0-9\\s.,?!/()áéíóúñÁÉÍÓÚÑ]'\n",
    "elif language == 'italian':\n",
    "    pattern= r'[^a-zA-Z0-9\\s.,?!/()àèéìòùÀÈÉÌÒÙ]'\n",
    "\n",
    "\n",
    "# Apply the regex pattern to clean the comments\n",
    "comments['Comment'] = comments['Comment'].apply(lambda x: re.sub(pattern, '', x))\n",
    "\n",
    "# Replace ., /, (, and ) with whitespace\n",
    "comments['Comment'] = comments['Comment'].apply(lambda x: re.sub(r'[.,/()]', ' ', x))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For inference comments, also do this :\n",
    "# Note that for the translated this is not necessary, as it was already done on the english comments and therefore\n",
    "# also the translated version\n",
    "\n",
    "\n",
    "# Remove trailing and excessive whitespaces\n",
    "comments['Comment'] = comments['Comment'].apply(lambda x: re.sub(r'\\s+', ' ', x).strip())\n",
    "# Remove comments with words like \"video\" and \"channel\" as they are associated with comments such as 'great video!'\n",
    "# Note we also need to remove from original, because in this case we are removing whole comments !\n",
    "if language == 'french':\n",
    "    comments = comments[~comments['Comment'].str.contains('vidéo|canal', case=False)]\n",
    "elif language == 'german':\n",
    "    comments = comments[~comments['Comment'].str.contains('video|kanal', case=False)]\n",
    "elif language == 'spanish':\n",
    "    comments = comments[~comments['Comment'].str.contains('video|canal', case=False)]\n",
    "elif language == 'italian':\n",
    "    comments = comments[~comments['Comment'].str.contains('video|canale', case=False)]\n",
    "\n",
    "    \n",
    "# Remove numbers from comments\n",
    "comments['Comment'] = comments['Comment'].apply(lambda x: re.sub(r'\\d+', '', x))\n",
    "# Remove words that have the scheme '@something' (i.e. remove words that begin with '@')\n",
    "comments['Comment'] = comments['Comment'].apply(lambda x: re.sub(r'@\\w+', '', x))\n",
    "# Remove trailing and excessive whitespaces\n",
    "comments['Comment'] = comments['Comment'].apply(lambda x: re.sub(r'\\s+', ' ', x).strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments.to_csv('Comments DB/{}/Finetuning/{}_combined_ready_for_finetuning.csv'.format(language,language), index=False)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
