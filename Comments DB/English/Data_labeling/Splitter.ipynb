{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Splitter\n",
        "\n",
        "In order to label the data, we shuffle the comments form different videos and select only 10000 comment to be labeled. Then, since we have 5 team member, we divide the balanced dataset into 5 parts of 2000 comments.\n"
      ],
      "metadata": {
        "id": "lVd-c1Iss0tb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "LbE4vRXlD9Wq"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Concat the files from different playlist"
      ],
      "metadata": {
        "id": "RxAqcW-IvhnI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We concatenate the files for each sentiment\n",
        "\n",
        "def concat_files(file_1, file_2):\n",
        "\n",
        "    # Load the data\n",
        "    df1 = pd.read_csv(file_1)\n",
        "    df2 = pd.read_csv(file_2)\n",
        "\n",
        "    # Concatenate the dataframes\n",
        "    df_concat = pd.concat([df1, df2], ignore_index=True)\n",
        "    return df_concat\n",
        "\n",
        "# Concat comment from positive playlist\n",
        "df_pos = concat_files('1_POSITIVE_ENGLISH_cleaned_and_filtered_comments_helper.csv',\n",
        "                      '2_POSITIVE_ENGLISH_cleaned_and_filtered_comments_helper.csv')\n",
        "\n",
        "# Concat comment from negative playlist\n",
        "df_neg = concat_files('1_NEGATIVE_ENGLISH_cleaned_and_filtered_comments_helper.csv',\n",
        "                      '2_NEGATIVE_ENGLISH_cleaned_and_filtered_comments_helper.csv')\n",
        "\n",
        "# Concat comment from neutral playlist\n",
        "df_neu = concat_files('1_NEUTRAL_ENGLISH_cleaned_and_filtered_comments_helper.csv',\n",
        "                      '2_NEUTRAL_ENGLISH_cleaned_and_filtered_comments_helper.csv')\n"
      ],
      "metadata": {
        "id": "sdxCKGxrrSUp"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create the dataset"
      ],
      "metadata": {
        "id": "aBICNBPJvVWn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We create a balanced dataset with 10,000 samples (3,333 for each category)\n",
        "\n",
        "def create_balanced_csv(df_pos, df_neg, df_neu, output_file, total_size):\n",
        "\n",
        "    # Print original size of the dataframes\n",
        "    print('Input Shape')\n",
        "    print('Pos: ', df_pos.shape)\n",
        "    print('Neg: ', df_neg.shape)\n",
        "    print('Neu: ', df_neu.shape)\n",
        "\n",
        "\n",
        "    # Calculate the size for each category\n",
        "    size = total_size // 3\n",
        "\n",
        "    # Randomly sample from each dataframe\n",
        "    df_pos_sample = df_pos.sample(n=min(size, len(df_pos)), random_state=1)\n",
        "    df_neg_sample = df_neg.sample(n=min(size, len(df_neg)), random_state=1)\n",
        "    df_neu_sample = df_neu.sample(n=min(size, len(df_neu)), random_state=1)\n",
        "\n",
        "    # If total size is not reached, add more samples from each category\n",
        "    while len(df_pos_sample) + len(df_neg_sample) + len(df_neu_sample) < total_size:\n",
        "        remaining = total_size - len(df_pos_sample) - len(df_neg_sample) - len(df_neu_sample)\n",
        "        to_add = min(remaining, size)\n",
        "        if len(df_pos) > len(df_pos_sample):\n",
        "            df_pos_sample = pd.concat([df_pos_sample, df_pos.loc[~df_pos.index.isin(df_pos_sample.index)].sample(n=to_add, random_state=1)])\n",
        "        elif len(df_neg) > len(df_neg_sample):\n",
        "            df_neg_sample = pd.concat([df_neg_sample, df_neg.loc[~df_neg.index.isin(df_neg_sample.index)].sample(n=to_add, random_state=1)])\n",
        "        else:\n",
        "            df_neu_sample = pd.concat([df_neu_sample, df_neu.loc[~df_neu.index.isin(df_neu_sample.index)].sample(n=to_add, random_state=1)])\n",
        "\n",
        "    # Concatenate the samples and shuffle\n",
        "    df_final = pd.concat([df_pos_sample, df_neg_sample, df_neu_sample])\n",
        "    df_final = df_final.sample(frac=1, random_state=1).reset_index(drop=True)\n",
        "\n",
        "    # Blank column to label\n",
        "    df_final[\"Label\"] = pd.NA\n",
        "\n",
        "    # Select only 'Dataset', 'Comment' and 'Label' columns\n",
        "    df_final = df_final[['Comment', 'Label']]\n",
        "\n",
        "    # Check the size\n",
        "    print('')\n",
        "    print('Output Shape')\n",
        "    print('Bal: ', df_final.shape)  # Should print (10000, 2)\n",
        "\n",
        "    # Save to csv\n",
        "    df_final.to_csv(output_file, index=False)\n",
        "\n",
        "# Call the function\n",
        "create_balanced_csv(df_pos, df_neg, df_neu, 'balanced.csv', 10000)\n"
      ],
      "metadata": {
        "id": "oxaqx8tYlNlF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17d789ee-9dd0-4c5b-a55b-f69e630c9d61"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input Shape\n",
            "Pos:  (3943, 2)\n",
            "Neg:  (8468, 2)\n",
            "Neu:  (8229, 2)\n",
            "\n",
            "Output Shape\n",
            "Bal:  (10000, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Divide the CSV in equal parts"
      ],
      "metadata": {
        "id": "65V-yaZXvMyg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Since we have 5 team members we divide the balanced dataset into 5 parts\n",
        "\n",
        "def divide_csv(input_file, num_parts):\n",
        "\n",
        "    # Load the data\n",
        "    df = pd.read_csv(input_file)\n",
        "\n",
        "    # Calculate the size of each part\n",
        "    part_size = len(df) // num_parts\n",
        "\n",
        "    print('Input Shape')\n",
        "    print('Df: ', df.shape)\n",
        "    print('')\n",
        "    print('Output Shape')\n",
        "\n",
        "    # Divide the dataframe into parts and save each one\n",
        "    for i in range(num_parts):\n",
        "        start = i * part_size\n",
        "        end = (i + 1) * part_size if i < num_parts - 1 else None  # Include remaining rows in the last part\n",
        "        df_part = df[start:end]\n",
        "\n",
        "        # Check the size\n",
        "        print(f'Part_{i+1}:', df_part.shape)  # Should print (2000,2)\n",
        "\n",
        "        # Download the csv\n",
        "        df_part.to_csv(f'part_{i+1}.csv', index=False)\n",
        "\n",
        "# Call the function\n",
        "divide_csv('balanced.csv', 5)\n"
      ],
      "metadata": {
        "id": "FtrOA0REk7wa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75e4794b-f00b-416b-934c-06d42d30c055"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input Shape\n",
            "Df:  (10000, 2)\n",
            "\n",
            "Output Shape\n",
            "Part_1: (2000, 2)\n",
            "Part_2: (2000, 2)\n",
            "Part_3: (2000, 2)\n",
            "Part_4: (2000, 2)\n",
            "Part_5: (2000, 2)\n"
          ]
        }
      ]
    }
  ]
}