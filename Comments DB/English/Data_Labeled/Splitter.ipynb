{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "LbE4vRXlD9Wq"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def concat_files(file_1, file_2):\n",
        "    df1 = pd.read_csv(file_1)\n",
        "    df2 = pd.read_csv(file_2)\n",
        "    # Concatenate the dataframes\n",
        "    df_concat = pd.concat([df1, df2], ignore_index=True)\n",
        "    return df_concat\n",
        "\n",
        "df_pos = concat_files('1_POSITIVE_ENGLISH_cleaned_and_filtered_comments_for_labeling_LABEL_HERE.csv',\n",
        "                           '2_POSITIVE_ENGLISH_cleaned_and_filtered_comments_for_labeling_LABEL_HERE.csv')\n",
        "\n",
        "df_neg = concat_files('1_NEGATIVE_ENGLISH_cleaned_and_filtered_comments_for_labeling_LABEL_HERE.csv',\n",
        "                           '2_NEGATIVE_ENGLISH_cleaned_and_filtered_comments_for_labeling_LABEL_HERE.csv')\n",
        "\n",
        "df_neu = concat_files('1_NEUTRAL_ENGLISH_cleaned_and_filtered_comments_for_labeling_LABEL_HERE.csv',\n",
        "                           '2_NEUTRAL_ENGLISH_cleaned_and_filtered_comments_for_labeling_LABEL_HERE.csv')\n"
      ],
      "metadata": {
        "id": "sdxCKGxrrSUp"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def create_balanced_csv(df_pos, df_neg, df_neu, output_file, total_size):\n",
        "    # Calculate the size for each category\n",
        "    size = total_size // 3\n",
        "\n",
        "    # Randomly sample from each dataframe\n",
        "    df_pos_sample = df_pos.sample(n=min(size, len(df_pos)), random_state=1)\n",
        "    df_neg_sample = df_neg.sample(n=min(size, len(df_neg)), random_state=1)\n",
        "    df_neu_sample = df_neu.sample(n=min(size, len(df_neu)), random_state=1)\n",
        "\n",
        "    # If total size is not reached, add more samples from each category\n",
        "    while len(df_pos_sample) + len(df_neg_sample) + len(df_neu_sample) < total_size:\n",
        "        remaining = total_size - len(df_pos_sample) - len(df_neg_sample) - len(df_neu_sample)\n",
        "        to_add = min(remaining, size)\n",
        "        if len(df_pos) > len(df_pos_sample):\n",
        "            df_pos_sample = pd.concat([df_pos_sample, df_pos.loc[~df_pos.index.isin(df_pos_sample.index)].sample(n=to_add, random_state=1)])\n",
        "        elif len(df_neg) > len(df_neg_sample):\n",
        "            df_neg_sample = pd.concat([df_neg_sample, df_neg.loc[~df_neg.index.isin(df_neg_sample.index)].sample(n=to_add, random_state=1)])\n",
        "        else:\n",
        "            df_neu_sample = pd.concat([df_neu_sample, df_neu.loc[~df_neu.index.isin(df_neu_sample.index)].sample(n=to_add, random_state=1)])\n",
        "\n",
        "    # Concatenate the samples and shuffle\n",
        "    df_final = pd.concat([df_pos_sample, df_neg_sample, df_neu_sample])\n",
        "    df_final = df_final.sample(frac=1, random_state=1).reset_index(drop=True)\n",
        "\n",
        "    # Blank column to label\n",
        "    df_final[\"Label\"] = pd.NA\n",
        "\n",
        "    # Select only 'Dataset', 'Comment' and 'Label' columns\n",
        "    df_final = df_final[['Comment', 'Label']]\n",
        "\n",
        "    print('Bal: ', df_final.shape)  # Should print (10000, 2)\n",
        "\n",
        "    # Save to csv\n",
        "    df_final.to_csv(output_file, index=False)\n",
        "\n",
        "# Call the function\n",
        "create_balanced_csv(df_pos, df_neg, df_neu, 'balanced.csv', 10000)\n"
      ],
      "metadata": {
        "id": "oxaqx8tYlNlF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "050cb0da-eda4-4717-b461-00eefd927df7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bal:  (10000, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def divide_csv(input_file, num_parts):\n",
        "    # Load the data\n",
        "    df = pd.read_csv(input_file)\n",
        "\n",
        "    # Calculate the size of each part\n",
        "    part_size = len(df) // num_parts\n",
        "\n",
        "    # Divide the dataframe into parts and save each one\n",
        "    for i in range(num_parts):\n",
        "        start = i * part_size\n",
        "        end = (i + 1) * part_size if i < num_parts - 1 else None  # Include remaining rows in the last part\n",
        "        df_part = df[start:end]\n",
        "        print(df_part.shape)\n",
        "        df_part.to_csv(f'part_{i+1}.csv', index=False)\n",
        "\n",
        "# Call the function\n",
        "divide_csv('balanced.csv', 5)\n"
      ],
      "metadata": {
        "id": "FtrOA0REk7wa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2749bc5f-de02-4054-9d93-9fac305640b3"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2000, 2)\n",
            "(2000, 2)\n",
            "(2000, 2)\n",
            "(2000, 2)\n",
            "(2000, 2)\n"
          ]
        }
      ]
    }
  ]
}