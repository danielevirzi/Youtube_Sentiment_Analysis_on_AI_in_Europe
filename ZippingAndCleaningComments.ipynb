{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[33mDEPRECATION: Loading egg at /opt/homebrew/lib/python3.11/site-packages/jupyter-1.0.0-py3.11.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting textblob\n",
            "  Downloading textblob-0.18.0.post0-py3-none-any.whl.metadata (4.5 kB)\n",
            "Requirement already satisfied: nltk>=3.8 in /opt/homebrew/lib/python3.11/site-packages (from textblob) (3.8.1)\n",
            "Requirement already satisfied: click in /opt/homebrew/lib/python3.11/site-packages (from nltk>=3.8->textblob) (8.1.4)\n",
            "Requirement already satisfied: joblib in /opt/homebrew/lib/python3.11/site-packages (from nltk>=3.8->textblob) (1.3.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /opt/homebrew/lib/python3.11/site-packages (from nltk>=3.8->textblob) (2023.8.8)\n",
            "Requirement already satisfied: tqdm in /opt/homebrew/lib/python3.11/site-packages (from nltk>=3.8->textblob) (4.65.0)\n",
            "Downloading textblob-0.18.0.post0-py3-none-any.whl (626 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m626.3/626.3 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: textblob\n",
            "Successfully installed textblob-0.18.0.post0\n"
          ]
        }
      ],
      "source": [
        "!pip install textblob"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "3GatpmKEhWiL"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import regex as re\n",
        "import glob\n",
        "import zipfile\n",
        "from textblob import TextBlob"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Read in your split of data\n",
        "all_english_comments = pd.read_csv('Comments DB/English/FINAL/splits_initial/comments_processed_split_0.csv')\n",
        "all_english_comments_original = pd.read_csv('Comments DB/English/FINAL/splits_initial/comments_original_split_0.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "2m33D4wphWiO"
      },
      "outputs": [],
      "source": [
        "# We saw after scraping that we still have some problematic comments, which we will now adress"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "W_N2JOnUhWiO"
      },
      "outputs": [],
      "source": [
        "# Remove comments with words like \"video\" and \"channel\" as they are associated with comments such as 'great video!'\n",
        "# Note we also need to remove from original, because in this case we are removing whole comments !\n",
        "all_english_comments = all_english_comments[~all_english_comments['Comment'].str.contains('video|channel', case=False)]\n",
        "all_english_comments_original = all_english_comments_original[~all_english_comments_original['Comment'].str.contains('video|channel', case=False)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "1VAdrs7yhWiO"
      },
      "outputs": [],
      "source": [
        "# Remove numbers from comments\n",
        "all_english_comments['Comment'] = all_english_comments['Comment'].apply(lambda x: re.sub(r'\\d+', '', x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "CoVZ6rCNhWiO"
      },
      "outputs": [],
      "source": [
        "# Remove words that have the scheme '@something' (i.e. remove words that begin with '@')\n",
        "all_english_comments['Comment'] = all_english_comments['Comment'].apply(lambda x: re.sub(r'@\\w+', '', x))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "420bbM7yhWiO"
      },
      "outputs": [],
      "source": [
        "# Replace special characters (all but period ('.') and whitespaces) with nothing (so they are removed)\n",
        "all_english_comments['Comment'] = all_english_comments['Comment'].apply(lambda x: re.sub(r'[^a-zA-Z0-9\\s.]', '', x))\n",
        "# Replace period with whitespace (so words are not getting merged)\n",
        "all_english_comments['Comment'] = all_english_comments['Comment'].apply(lambda x: re.sub(r'\\.', ' ', x))\n",
        "# Remove trailing whitespaces\n",
        "all_english_comments['Comment'] = all_english_comments['Comment'].apply(lambda x: re.sub(r'\\s+', ' ', x).strip())\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "# We also aim to fix spelling mistakes, as they can mess up our sentiment analysis heavily (we tested that on some models and got completely wrong sentiments due to spelling mistakes)\n",
        "# This we can also do on the original comments directly \n",
        "# This will later on also be crucial for translation into other languages !\n",
        "\n",
        "# Function to correct spelling mistakes\n",
        "def correct_spelling(text):\n",
        "    try:\n",
        "        corrected_text = str(TextBlob(text).correct())\n",
        "        return corrected_text\n",
        "    except Exception as e:\n",
        "        return text\n",
        "    \n",
        "all_english_comments['Comment'] = all_english_comments['Comment'].apply(correct_spelling)\n",
        "all_english_comments_original['Comment'] = all_english_comments_original['Comment'].apply(correct_spelling)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "XC_2ByzjhWiO"
      },
      "outputs": [],
      "source": [
        "# We first need to concatenate the two dataframes\n",
        "# We will then drop duplicates\n",
        "# We will then split them again\n",
        "\n",
        "all_english_comments_combined = pd.concat([all_english_comments.reset_index(drop=True), all_english_comments_original.reset_index(drop=True)], axis = 1)\n",
        "all_english_comments_combined.columns = ['Comment processed', 'Comment original']\n",
        "all_english_comments_combined = all_english_comments_combined.drop_duplicates(subset='Comment processed', keep='first')\n",
        "# Split the dataframes again\n",
        "all_english_comments = all_english_comments_combined[['Comment processed']].rename(columns={'Comment processed': 'Comment'})\n",
        "all_english_comments_original = all_english_comments_combined[['Comment original']].rename(columns={'Comment original': 'Comment'})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Mn4li3w3hWiO"
      },
      "outputs": [],
      "source": [
        "# Save to csv\n",
        "all_english_comments.to_csv('Comments DB/English/FINAL/splits_processed/comments_processed_split_0.csv')\n",
        "all_english_comments_original.to_csv('Comments DB/English/FINAL/splits_processed/comments_original_split_0.csv')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
