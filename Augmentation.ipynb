{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import PegasusForConditionalGeneration, PegasusTokenizer\n",
    "from google.colab import files\n",
    "from google.colab import drive\n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open a file upload dialog\n",
    "# Select here all files to upload!\n",
    "# If already uploaded, just press 'Cancel Upload'\n",
    "uploaded = files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the path to the data\n",
    "# On local machine use the relative path, for example\n",
    "# path = 'NLP labelled data preview/english set/'\n",
    "# On Google Colab use this path\n",
    "# '/content/'\n",
    "path = '/content/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "file = 'High_Confidence_Comments_Original_English.csv'\n",
    "all_comments = pd.read_csv(path + file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Tokenizer and model \n",
    "tokenizer = PegasusTokenizer.from_pretrained('tuner007/pegasus_paraphrase')\n",
    "model = PegasusForConditionalGeneration.from_pretrained('tuner007/pegasus_paraphrase')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to use GPU \n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_response(input_text,num_return_sequences,num_beams):\n",
    "  batch = tokenizer([input_text],truncation=True,padding='longest',max_length=60, return_tensors=\"pt\").to(device)\n",
    "  translated = model.generate(**batch,max_length=60,num_beams=num_beams, num_return_sequences=num_return_sequences, temperature=1.5)\n",
    "  tgt_text = tokenizer.batch_decode(translated, skip_special_tokens=True)\n",
    "  return tgt_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate paraphrases and expand DataFrame\n",
    "# We want to add the paraphrased comments right under the original comment, for each comment respectively\n",
    "def expand_comments(df, num_return_sequences, num_beams):\n",
    "    new_rows = []\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        original_comment = row['Comment']\n",
    "        label = row['Label']  # Change 'labels' to 'Label'\n",
    "        new_rows.append({'Comment': original_comment, 'Label': label})  # Change 'labels' to 'Label'\n",
    "        \n",
    "        generated_comments = get_response(original_comment, num_return_sequences, num_beams)\n",
    "        \n",
    "        for gen_comment in generated_comments:\n",
    "            new_rows.append({'Comment': gen_comment, 'Label': label})  # Change 'labels' to 'Label'\n",
    "    \n",
    "    expanded_df = pd.DataFrame(new_rows)\n",
    "    expanded_df.reset_index(drop=True, inplace=True)\n",
    "    return expanded_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_beams = 10 # parameter for beam search, a search strategy used to generate sequences in language generation tasks\n",
    "num_return_sequences = 10 # How many different sequences to generate\n",
    "\n",
    "comments_augmented = expand_comments(all_comments, num_return_sequences, num_beams)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_augmented.to_csv(path + 'High_Confidence_Comments_Original_English_Augmented.csv', index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the file to your local machine (from google colab)\n",
    "files.download(path + 'High_Confidence_Comments_Original_English_Augmented.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
