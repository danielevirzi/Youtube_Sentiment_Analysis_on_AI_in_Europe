{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import PegasusForConditionalGeneration, PegasusTokenizer\n",
    "from google.colab import files\n",
    "from google.colab import drive\n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open a file upload dialog\n",
    "# Select here all files to upload!\n",
    "# If already uploaded, just press 'Cancel Upload'\n",
    "uploaded = files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the path to the data\n",
    "# On local machine use the relative path, for example\n",
    "# path = 'NLP labelled data preview/english set/'\n",
    "# On Google Colab use this path\n",
    "# '/content/'\n",
    "path = '/content/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "file = 'combined_original_90_to_95.csv'\n",
    "all_comments = pd.read_csv(path + file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "removed_rows = []\n",
    "# We want to augment such that we keep the original balance of our dataset\n",
    "if all_comments['Label'].value_counts()[0] > all_comments['Label'].value_counts()[2]:\n",
    "    # Get the difference in labels\n",
    "    diff = all_comments['Label'].value_counts()[0] - all_comments['Label'].value_counts()[2]\n",
    "    for i in range(diff):\n",
    "        # Remove random rows with label '0', but save it for later\n",
    "        sampled_row = all_comments[all_comments['Label'] == 0].sample()\n",
    "\n",
    "        # Append the sampled row to the list of removed rows\n",
    "        removed_rows.append(sampled_row)\n",
    "\n",
    "        # Drop the sampled row from the original DataFrame\n",
    "        all_comments = all_comments.drop(sampled_row.index)\n",
    "        \n",
    "        \n",
    "\n",
    "else:\n",
    "    # Get the difference in labels\n",
    "    diff = all_comments['Label'].value_counts()[2] - all_comments['Label'].value_counts()[0]\n",
    "    for i in range(diff):\n",
    "        # Remove random rows with label '2', but save it for later\n",
    "        sampled_row = all_comments[all_comments['Label'] == 2].sample()\n",
    "\n",
    "        # Append the sampled row to the list of removed rows\n",
    "        removed_rows.append(sampled_row)\n",
    "\n",
    "        # Drop the sampled row from the original DataFrame\n",
    "        all_comments = all_comments.drop(sampled_row.index)\n",
    "\n",
    "\n",
    "# Concatenate the list of removed rows into a single DataFrame\n",
    "removed_rows_df = pd.concat(removed_rows).reset_index(drop=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Tokenizer and model \n",
    "tokenizer = PegasusTokenizer.from_pretrained('tuner007/pegasus_paraphrase')\n",
    "model = PegasusForConditionalGeneration.from_pretrained('tuner007/pegasus_paraphrase')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to use GPU \n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_response(input_text,num_return_sequences,num_beams):\n",
    "  batch = tokenizer([input_text],truncation=True,padding='longest',max_length=60, return_tensors=\"pt\").to(device)\n",
    "  translated = model.generate(**batch,max_length=60,num_beams=num_beams, num_return_sequences=num_return_sequences, temperature=1.5)\n",
    "  tgt_text = tokenizer.batch_decode(translated, skip_special_tokens=True)\n",
    "  return tgt_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate paraphrases and expand DataFrame\n",
    "# We want to add the paraphrased comments right under the original comment, for each comment respectively\n",
    "def expand_comments(df, num_return_sequences, num_beams):\n",
    "    new_rows = []\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        original_comment = row['Comment']\n",
    "        label = row['Label']  # Change 'labels' to 'Label'\n",
    "        score = row['Score']\n",
    "        new_rows.append({'Comment': original_comment, 'Label': label, 'Score': score})  \n",
    "        \n",
    "        generated_comments = get_response(original_comment, num_return_sequences, num_beams)\n",
    "        \n",
    "        for gen_comment in generated_comments:\n",
    "            new_rows.append({'Comment': gen_comment, 'Label': label, 'Score': score})  \n",
    "    \n",
    "    expanded_df = pd.DataFrame(new_rows)\n",
    "    expanded_df.reset_index(drop=True, inplace=True)\n",
    "    return expanded_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_beams = 10 # parameter for beam search, a search strategy used to generate sequences in language generation tasks\n",
    "num_return_sequences = 2 # How many different sequences to generate\n",
    "\n",
    "comments_augmented = expand_comments(all_comments, num_return_sequences, num_beams)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the augmented comments dataframe and the removed rows dataframe together again\n",
    "all_comments_augmented = pd.concat([comments_augmented, removed_rows_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_comments_augmented.to_csv(path + 'combined_original_90_to_95_augmented.csv', index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the file to your local machine (from google colab)\n",
    "files.download(path + 'combined_original_90_to_95_augmented.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
